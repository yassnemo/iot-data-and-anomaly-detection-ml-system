services:
  # Kafka (KRaft mode - no Zookeeper needed)
  kafka:
    image: apache/kafka:latest
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 10
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
    volumes:
      - kafka-data:/var/lib/kafka/data

  # MinIO (S3-compatible object storage)
  minio:
    image: minio/minio:latest
    hostname: minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Create MinIO bucket on startup
  minio-init:
    image: minio/mc:latest
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb myminio/iot-data --ignore-existing;
      mc mb myminio/models --ignore-existing;
      exit 0;
      "

  # Spark Master
  spark-master:
    image: apache/spark:3.5.0
    hostname: spark-master
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    volumes:
      - ./src:/app/src
      - ./models:/models
      - spark-checkpoints:/tmp/spark-checkpoints

  # Spark Worker
  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=4G
      - SPARK_WORKER_CORES=4
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    volumes:
      - ./src:/app/src
      - ./models:/models
      - spark-checkpoints:/tmp/spark-checkpoints

  # TensorFlow Serving
  tfserving:
    image: tensorflow/serving:latest
    hostname: tfserving
    container_name: tfserving
    ports:
      - "8501:8501"
      - "8500:8500"
    environment:
      MODEL_NAME: anomaly_detector
    volumes:
      - ./models:/models
    command: --model_base_path=/models/anomaly_detector --rest_api_port=8501 --model_config_file=/models/models.config
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/v1/models/anomaly_detector"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    hostname: prometheus
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Grafana
  grafana:
    image: grafana/grafana:latest
    hostname: grafana
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=
    volumes:
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Producer (Sensor Simulator)
  producer:
    build:
      context: .
      dockerfile: Dockerfile
    hostname: producer
    container_name: producer
    depends_on:
      - kafka
      - minio
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - NUM_SENSORS=10000
      - MESSAGES_PER_SECOND=1
      - ANOMALY_RATE=0.05
    volumes:
      - ./src:/app/src
      - ./scripts:/app/scripts
      - ./data:/app/data
    command: tail -f /dev/null  # Keep container running

  # Trainer
  trainer:
    build:
      context: .
      dockerfile: Dockerfile
    hostname: trainer
    container_name: trainer
    depends_on:
      - minio
    environment:
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
    volumes:
      - ./src:/app/src
      - ./models:/app/models
      - ./data:/app/data
    command: tail -f /dev/null  # Keep container running

volumes:
  kafka-data:
  minio-data:
  prometheus-data:
  grafana-data:
  spark-checkpoints:

networks:
  default:
    name: iot-anomaly-network
